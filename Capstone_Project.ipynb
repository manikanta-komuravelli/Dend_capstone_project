{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Tweets during US elections 2020 \n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, I try to analyse the tweets during the US elections of 2020 which had Trump and Biden in their hashtags. \n",
    "\n",
    "\n",
    "#### Project Scope\n",
    "I try to figure out the tweet timings, and get the user details to understand which states have more tweets for each Presidential candidate. And also, bring in the population of each state to understand more about the ratio of people tweeting from each state.\n",
    "Data sets (Twitter data with hashtags) are gathered from Kaggle and the population data set from dataworld. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, LongType, DoubleType, FloatType\n",
    "from pyspark.sql.functions import lit, udf, col, to_timestamp, to_date, monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating Spark Session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exploring And Assessing Data:\n",
    "I’m using Spark as my big data framework and its libraries to do my data extraction and transformation. \n",
    "Exploration and Assessment of data includes various steps from fetching the data properly, assigning proper data types for each column, dropping the duplicates, removing the null values and grouping the data together for the creation of a data model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Extracting the Data from the data sources and creating a spark data frame to load and transform the data\n",
    "Steps Followed:\n",
    "1. Created a schema to be used for extraction of the data from the data sets\n",
    "2. Loaded the dataset with trump hashtags\n",
    "3. Loaded the dataset with Biden hashtags\n",
    "4. Cleaned the datasets and combined them to form a single dataset with all the tweets\n",
    "5. Loaded the population dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_schema= StructType([ StructField(\"created_at\", StringType(), True)\\\n",
    "                       ,StructField(\"tweet_id\", DoubleType(), False)\\\n",
    "                       ,StructField(\"tweet\", StringType(), True)\\\n",
    "                       ,StructField(\"likes\", FloatType(), True)\\\n",
    "                       ,StructField(\"retweet_count\", FloatType(), True)\\\n",
    "                       ,StructField(\"source\", StringType(), True)\\\n",
    "                       ,StructField(\"user_id\", DoubleType(), True)\\\n",
    "                       ,StructField(\"user_name\", StringType(), True)\\\n",
    "                       ,StructField(\"user_screen_name\", StringType(), True)\\\n",
    "                       ,StructField(\"user_description\", StringType(), True)\\\n",
    "                       ,StructField(\"user_join_date\", StringType(), True)\\\n",
    "                       ,StructField(\"user_followers_count\", DoubleType(), True)\\\n",
    "                       ,StructField(\"user_location\", StringType(), True)\\\n",
    "                       ,StructField(\"lat\", FloatType(), True)\\\n",
    "                       ,StructField(\"long\", FloatType(), True)\\\n",
    "                       ,StructField(\"city\", StringType(), True)\\\n",
    "                       ,StructField(\"country\", StringType(), True)\\\n",
    "                       ,StructField(\"continent\", StringType(), True)\\\n",
    "                       ,StructField(\"state\", StringType(), True)\\\n",
    "                       ,StructField(\"state_code\", StringType(), True)\\\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Extracting trump data\n",
    "file_path_trump= 'Twitter_Data/hashtag_donaldtrump.csv'\n",
    "df_trump= spark.read.format(\"csv\").option(\"header\", True).option('delimiter', \",\").schema(my_schema).option('multiLine', True).load(file_path_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Extracting biden data\n",
    "file_path_biden= 'Twitter_Data/hashtag_joebiden.csv'\n",
    "df_biden= spark.read.format(\"csv\").option(\"header\", True).option('delimiter', \",\").schema(my_schema).option('multiLine', True).load(file_path_biden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- tweet_id: double (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- likes: float (nullable = true)\n",
      " |-- retweet_count: float (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_id: double (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- user_description: string (nullable = true)\n",
      " |-- user_join_date: string (nullable = true)\n",
      " |-- user_followers_count: double (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- hashtag_type: string (nullable = false)\n",
      "\n",
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- tweet_id: double (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- likes: float (nullable = true)\n",
      " |-- retweet_count: float (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_id: double (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- user_description: string (nullable = true)\n",
      " |-- user_join_date: string (nullable = true)\n",
      " |-- user_followers_count: double (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- hashtag_type: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding a hashtag column for both the datasets\n",
    "df_trump= df_trump.withColumn(\"hashtag_type\",lit(\"Trump\"))\n",
    "df_trump.printSchema()\n",
    "df_biden= df_biden.withColumn(\"hashtag_type\",lit(\"Biden\"))\n",
    "df_biden.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#combining both the dataframes\n",
    "df_tweets= df_biden.union(df_trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#creating a timestamp column from the existing timestamp as string\n",
    "df_tweets= df_tweets.withColumn(\"tweet_staging_time\", to_timestamp(col('created_at'), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Cleaning the data from Null values\n",
    "df_tweets= df_tweets.na.drop(subset=['tweet_id','user_id','tweet_staging_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- tweet_id: double (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- likes: float (nullable = true)\n",
      " |-- retweet_count: float (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_id: double (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- user_description: string (nullable = true)\n",
      " |-- user_join_date: string (nullable = true)\n",
      " |-- user_followers_count: double (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- hashtag_type: string (nullable = false)\n",
      " |-- tweet_time: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1682732"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.printSchema()\n",
    "df_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Reading the json file with US state population data to be used later\n",
    "spark_pop= spark.read.json('us_population.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Defining a Data Model:\n",
    "\n",
    "I’m trying to define a data model with 5 dimension tables and 1 fact table\n",
    "\n",
    "1st Dimension table- User details: This table contains user details such as user_id, user_name, user_description, user_screen_name, user_followers_count.\n",
    "\n",
    "2nd Dimension table- twitter_details: This table contains twitter information such as tweet_id, likes, retweets, tweet, tweet source.\n",
    "\n",
    "3rd Dimension table- time_details: This table contains time details of the tweet such as tweet_time, hour, day, week, month, day of the week.\n",
    "\n",
    "4th Dimension table- location_details: This table contains location details of the tweet such as location, latitude, longitude, state, country\n",
    "\n",
    "5th Dimension table- population_details: This table contains population details of the US states such as  state_name, population \n",
    "\n",
    "Fact table- tweet details: This is the fact table which contains details such as user_id, tweet_id, tweet, hashtag, tweet_time, tweet_location, week_of the tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creation of user table\n",
    "df_users= df_tweets.select([\"user_id\",\"user_name\",\"user_screen_name\",\"user_description\",\"user_followers_count\"]).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: double (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- user_description: string (nullable = true)\n",
      " |-- user_followers_count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: double (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- likes: float (nullable = true)\n",
      " |-- retweet_count: float (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creation of twitter details table\n",
    "df_twitter= df_tweets.select([\"tweet_id\",\"tweet\",\"likes\",\"retweet_count\",\"source\"]).dropDuplicates()\n",
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creation of time table\n",
    "df_time= df_tweets.select([\"created_at\"])\n",
    "df_time.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating a timestamp and making a final time table\n",
    "df_time= df_time.withColumn(\"tweet_time\", to_timestamp(col('created_at'), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "df_time= df_time.withColumn(\"Date\",to_date(col('tweet_time')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time= df_time.selectExpr(['tweet_time as tweet_time',\n",
    "                            'hour(Date) as hour',\n",
    "                            'dayofmonth(Date) as day',\n",
    "                            'weekofyear(Date) as week',\n",
    "                            'month(Date) as month',\n",
    "                            'dayofweek(Date) as weekday',\n",
    "                            ])\n",
    "df_time.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating Location table \n",
    "df_location= df_tweets.select(['user_location','lat','long','country','state'])\n",
    "df_location= df_location.na.drop(subset=['user_location','state'])\n",
    "df_location.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Pipeline and Fact table Creation\n",
    "After defining the data model above, I’ve used the staged data from the spark dataframe and loaded them into the corresponding tables to be used for further analysis.\n",
    "\n",
    "The fact table is created from the extracted data with the model mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Reading the json file with US state population data to be used later\n",
    "spark_pop= spark.read.json('us_population.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- nyt_population: string (nullable = true)\n",
      " |-- population: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- subregion: string (nullable = true)\n",
      " |-- us_county_fips: string (nullable = true)\n",
      " |-- us_state_fips: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- nyt_population: string (nullable = true)\n",
      " |-- population: double (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- subregion: string (nullable = true)\n",
      " |-- us_county_fips: string (nullable = true)\n",
      " |-- us_state_fips: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_pop.printSchema()\n",
    "spark_pop= spark_pop.withColumn(\"population\",spark_pop['population'].cast('double'))\n",
    "spark_pop.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#Grouping by region to calculate the population for each state and creating a new spark dataframe which contains only required details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "population_df= spark_pop.groupBy('region').sum('population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- region: string (nullable = true)\n",
      " |-- Population: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4864680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>738516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>6946685.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2990671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>39148760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>5531141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3581504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>949495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>684498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>20598139.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 region  Population\n",
       "0               Alabama   4864680.0\n",
       "1                Alaska    738516.0\n",
       "2               Arizona   6946685.0\n",
       "3              Arkansas   2990671.0\n",
       "4            California  39148760.0\n",
       "5              Colorado   5531141.0\n",
       "6           Connecticut   3581504.0\n",
       "7              Delaware    949495.0\n",
       "8  District of Columbia    684498.0\n",
       "9               Florida  20598139.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df= population_df.withColumn(\"Population\",population_df[\"sum(population)\"]).drop(\"sum(population)\").na.drop(subset=[\"region\"])\n",
    "population_df.printSchema()\n",
    "population_df.orderBy('region').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#Reading tweets containg Trump as the hashtag\n",
    "Also cleaning the data with none values, dropping duplicates, creating a proper schema for importing data and storing it in trump dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
